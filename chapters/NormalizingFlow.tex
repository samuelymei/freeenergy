% !TeX spellcheck = en_US
\subsection{Normalizing Flow\label{Sec:FEM:NF}}
In 2002, Jarzynski proposed a generalized free energy perturbation method termed ``targeted free energy perturbation''.\cite{JarzynskiPRE2002} This method generalizes the free energy perturbation method between two states, $A$ and $B$, by introducing an intermediate state $A^\prime(\mathbf{y})$ by mapping $\mathcal{M}$ from the microstate of the system $\mathbf{x}$ to another one $\mathbf{y}$ in the configuration space or phase space
\begin{equation}
	\mathcal{M}: \mathbf{x} \to \mathbf{y}(\mathbf{x}),
\end{equation}
The potential energy function of the mapped state $A^\prime(\mathbf{y})$ is
\begin{equation}
	U_{A^\prime}(\mathbf{y})=U_A(\mathbf{x})+\beta^{-1}\ln J(\mathbf{x}),
\end{equation}
where $J(\mathbf{x})=|\partial \mathbf{y}/\partial \mathbf{x}|$ is the Jacobian of the mapping $\mathcal{M}$. Zhu et al also used this transformation, but for enhancing conformational sampling.\cite{ZhuPRL2002} The Helmholtz free energy difference between state $A$ and state $A^\prime$ is zero by noticing that
\begin{align*}
	\Delta F_{A^\prime A}=&-\beta^{-1}\ln\frac{Z_{A^\prime}}{Z_A}\notag\\
	=&-\beta^{-1}\ln \frac{\displaystyle\int e^{-\beta U_{A^\prime}(\mathbf{y})}\diff y}{Z_A}\notag\\
	=&-\beta^{-1}\ln \frac{\displaystyle\int e^{-\beta (U_{A^\prime}(\mathbf{y})-U_A(\mathbf{x}))}e^{-\beta U_A(\mathbf{x})}\diff y}{Z_A}\notag\\
	=&-\beta^{-1}\ln \frac{\displaystyle\int J^{-1}(\mathbf{x})e^{-\beta U_A(\mathbf{x})}\diff y}{Z_A}\notag\\
	=&-\beta^{-1}\ln \frac{\displaystyle\int e^{-\beta U_A(\mathbf{x})}\diff x}{Z_A}\notag\\
	=&0.
\end{align*}
The calculation of the free energy difference between state $A$ and state $B$ can be replaced by the calculation of free energy difference between state $A^\prime$ and state $B$. The latter can be written as
\begin{align}
	\Delta F_{BA^\prime}=&-\beta^{-1}\ln {\int e^{-\beta (U_B(\mathbf{y})-U_{A^\prime}(\mathbf{y}))}\rho_{A^\prime}(\mathbf{y})\diff \mathbf{y}}\notag\\
	=&-\beta^{-1}\ln {\int e^{-\beta \Phi(\mathbf{x})}\rho_{A}(\mathbf{x})\diff \mathbf{x}}
\end{align}
in which 
\begin{align}
	\Phi(\mathbf{x})\equiv& U_B(\mathbf{y}) - U_{A^\prime}(\mathbf{y})\notag\\
	=&U_B(\mathbf{y})-U_A(\mathbf{x})-\beta^{-1}\ln J(\mathbf{x}),
	\label{Eq:FEM:TP:TFEPPhi}
\end{align}
and the relationship between the distributions
\begin{equation}
	\rho_{A^\prime}(\mathbf{y})=\rho_{A}(\mathbf{x})/J(\mathbf{x})
	\label{Eq:FEM:TP:TFEPdistribution}
\end{equation}
has been invoked.

As a special case $\mathcal{M}: \mathbf{x} \to\mathbf{x}$,
\begin{equation}
	\Phi(\mathbf{x})\equiv U_B(\mathbf{x})-U_A(\mathbf{x}),
\end{equation}
and it reduces to the traditional free energy perturbation. It implies that there may exist an invertible mapping $\mathcal{M}$ for which the average of $\exp\{-\beta \Phi\}$ converges more rapidly than the average of $\exp\{-\beta (U_B-U_A)\}$. It can also be asserted that
\begin{align}
	e^{-\beta \Delta F}=&\left<e^{-\beta \Phi}\right>_A\notag\\
	=&\int \diff \mathbf{x}\, \rho(\mathbf{x})e^{-\beta \Phi(\mathbf{x})}\notag\\
	=&\int \diff\phi \int \diff \mathbf{x}\, \rho(\mathbf{x})e^{-\beta \Phi(\mathbf{x})}\delta(\Phi(\mathbf{x})-\phi)\notag\\
	=&\int \diff\phi\, e^{-\beta \phi}\int \rho(\mathbf{x})\delta(\Phi(\mathbf{x})-\phi)\diff \mathbf{x}\notag\\
	=&\int \diff\phi\, e^{-\beta \phi} p(\phi|\mathcal{M}),
\end{align}
where $p(\phi|\mathcal{M})$ is the distribution of values of $\phi=\Phi(\mathbf{x})$ for $\mathbf{x}$ sampled from $A$. In practice, $\Delta F$ can be estimated by averaging $\exp{(-\beta \Phi)}$ over a finite number of sampled microstates $\mathbf{x}_1,\,\mathbf{x}_2,\dots,\mathbf{x}_N$
\begin{equation}
	\Delta F=-\beta^{-1}\ln\frac{1}{N}\sum_{n=1}^N e^{-\beta \Phi(\mathbf{x}_n)}.
\end{equation}
The rate of convergence depends on the choice of $\mathcal{M}$. With a perfect mapping $\mathcal{M}^\ast$ that transforms $A$ exactly onto $B$, we will find from Eq.~\ref{Eq:FEM:TP:TFEPdistribution} that
\begin{equation}
	\frac{1}{Z_B}e^{-\beta U_B(\mathbf{y})}=\frac{1}{Z_A}e^{-\beta U_A(\mathbf{x})}/J(\mathbf{x}).
\end{equation}
By taking it into Eq.~\ref{Eq:FEM:TP:TFEPPhi}, we will have
\begin{equation}
	\Phi(\mathbf{x})=\Delta F,
\end{equation}
which means
\begin{equation}
	p(\phi|\mathcal{M}^\ast)=\delta (\phi-\Delta F).
\end{equation}
Then the convergence of the finite sampling is immediate: $\Phi(\mathbf{x})=\Delta F$ for every sampled $\mathbf{x}$. Although constructing a perfect transformation is usually impossible for real-world problems, a transformation that keeps a narrow distribution of $\phi$'s, which implies good overlap between the transformed state and state $B$, can accelerate the convergence of the generalized free energy perturbation calculations.

Recently, Rizzi et al. showed that if the samples are used for both the optimization/learning of the mapping, it will cause systematic error in the calculated free energy change.\cite{RizziJPCL2021} They suggested to use a small data set for learning and a large set for evaluating the free energy change.

In 2009, Hahn and Then extended this idea and proposed a bidirectional formulation as a generalized Bennett Acceptance Ratio method\cite{HahnPRE2009}.
They began with the identity, which can be easily obtained from Eq.~\ref{Eq:FEM:TP:TFEPPhi},
\begin{equation}
	\frac{\rho_{A^\prime}(\mathbf{y}(\mathbf{x}))}{\rho_B(\mathbf{y}(\mathbf{x}))}=e^{\beta\left[\Phi(\mathbf{x})-\Delta F\right]}\qquad \forall \mathbf{x}\in \Gamma_A.
\end{equation}
Multiplying both sides with $\delta [W-\Phi(\mathbf{x})]\rho_B(\mathbf{y}(\mathbf{x}))$ and integrating with respect to $\mathbf{y}$, the left-hand side yields
\begin{align}
	\int_{\mathbf{y}(\Gamma_A)}&\delta[W-\Phi(\mathbf{x})]\rho_{A^\prime}(\mathbf{y}(\mathbf{x}))\diff \mathbf{y}\notag\\
	=&\int_{\Gamma_A}\delta[W-\Phi(\mathbf{x})]\rho_A(\mathbf{x})\diff \mathbf{x}\notag\\
	=&p(W|A;\mathcal{M}),
\end{align}
and the right-hand side yields
\begin{align}
	\int_{\mathbf{y}(\Gamma_A)}&e^{\beta\left[\Phi(\mathbf{x})-\Delta F\right]}\delta[W-\Phi(\mathbf{x})]\rho_B(\mathbf{y})\diff \mathbf{y}\notag\\
	=&e^{\beta\left[W-\Delta F\right]}\int_{\mathbf{y}(\Gamma_A)}\delta[W-\Phi(\mathbf{x})]\rho_B(\mathbf{y})\diff \mathbf{y}\notag\\
	=&e^{\beta\left[W-\Delta F\right]}p(W|B;\mathcal{M}),
\end{align}
where $p(W|A;\mathcal{M})$ ($p(W|B;\mathcal{M})$) is the probability density for the outcome of a specific value of the generalized work $W$ in forward (reverse) direction subject to the map $\mathcal{M}$ when sampled from $\rho_A$ ($\rho_B$). Then, we arrive at the fluctuation theorem for any differentiable, bijective map $\mathcal{M}$ from $\Gamma_A$ to $\Gamma_B$
\begin{equation}
	\frac{p(W|A;\mathcal{M})}{p(W|B;\mathcal{M})}=e^{\beta\left[W-\Delta F\right]}.
	\label{Eq:FEM:TP:FluctTheo}
\end{equation}
Bayes theorem,
\begin{equation}
	p(W|Y)p_Y=p(Y|W)p(W), \quad \text{with $Y=A$ or $B$}
	\label{Eq:FEM:TP:Bayes}
\end{equation}
implies the ``balance'' equation
\begin{align}
	p_B\int p(A|W)p(W|B)\diff W=&\int p(A|W)p(B|W)p(W)\diff W\notag\\
	=&\int p(B|W)p(W|A)p_A\diff W\notag\\
	=&p_A\int p(B|W)p(W|A)\diff W,
	\label{Eq:FEM:TP:BalEq}
\end{align}
or $p_B\left<p(A|W)\right>_B=p_A\left<p(B|W)\right>_A$.

Combining Eq.~\ref{Eq:FEM:TP:FluctTheo} and Eq.~\ref{Eq:FEM:TP:Bayes} leads to
\begin{equation}
	\frac{p(A|W)}{p(B|W)}=e^{\beta(W-C)}
\end{equation}
with
\begin{equation}
	C=\Delta F+\frac{1}{\beta}\ln{\frac{p_B}{p_A}}.
\end{equation}
With the normalization condition $p(A|W)+p(B|W)=1$, it yields
\begin{equation}
	p(A|W)=\frac{1}{1+e^{\beta(C-W)}}
\end{equation}
and
\begin{equation}
	p(B|W)=\frac{e^{\beta(C-W)}}{1+e^{\beta(C-W)}}=\frac{1}{1+e^{\beta(-C+W)}}.
\end{equation}
Replacing both, the ensemble averages by sample averages and the ratio $\frac{p_B}{p_A}$ by $\frac{n_B}{n_A}$, the balance equation Eq.~\ref{Eq:FEM:TP:BalEq} results in
\begin{equation}
	\sum_{j=1}^{n_B}\frac{1}{1+\frac{n_B}{n_A}\exp{\left(\beta\widehat{\Delta F}_{AB}-\beta W^j_B\right)}}=	\sum_{i=1}^{n_A}\frac{1}{1+\frac{n_B}{n_A}\exp{\left(-\beta\widehat{\Delta F}_{AB}+\beta W^i_A\right)}}.
\end{equation}
They also suggested using Kullback-Leibler divergence to characterize the similarity between the mapped state $A^\prime$ and state $B$.

Paliwal and Shirts combined this idea of mapping in configurational space with MBAR.\cite{PaliwalJCP2013}

Ding and Zhang further extended this idea and integrated BAR with a deep generative model and developed an efficient free energy method DeepBAR.\cite{DingJPCL2021}